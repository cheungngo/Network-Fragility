{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNtCnBNl5E+wbBBMWZd53DL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Modes of Antidepressants"],"metadata":{"id":"DwrVmbnd0Tr0"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gm4ZPsxV0TCJ","executionInfo":{"status":"ok","timestamp":1768736159248,"user_tz":-480,"elapsed":241733,"user":{"displayName":"Ngo Cheung","userId":"02091267041339546959"}},"outputId":"8ff67243-fe96-4609-b736-1df56f733ac9"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","################################################################################\n","#                                                                              #\n","#                  MULTI-MECHANISM ANTIDEPRESSANT COMPARISON                   #\n","#                       Ketamine vs SSRI vs Neurosteroid                       #\n","#                                                                              #\n","################################################################################\n","\n","================================================================================\n","  MULTI-MECHANISM ANTIDEPRESSANT COMPARISON EXPERIMENT\n","================================================================================\n","\n","  COMPARING THREE ANTIDEPRESSANT MECHANISMS:\n","  \n","  ┌─────────────────┬─────────────────────────────────────────────────────────┐\n","  │ Mechanism       │ Key Feature                                             │\n","  ├─────────────────┼─────────────────────────────────────────────────────────┤\n","  │ Ketamine        │ Gradient-guided synaptogenesis (↑ density)              │\n","  │ SSRI            │ Gradual noise reduction (stabilizes existing weights)   │\n","  │ Neurosteroid    │ Tonic inhibition (damps activity, bounds firing)        │\n","  └─────────────────┴─────────────────────────────────────────────────────────┘\n","  \n","  All treatments start from identical 95% sparse (depressed) networks.\n","    \n","----------------------------------------------------------------------\n","  Preparing shared pruned baseline...\n","----------------------------------------------------------------------\n","  Training full network (20 epochs)...\n","  Pruned to 95.0% sparse\n","\n","  UNTREATED PRUNED STATE:\n","    Clean: 50.8%\n","    Standard: 43.9%\n","    Combined stress: 31.8%\n","    Extreme stress: 28.3%\n","\n","======================================================================\n","  TREATMENT 1: KETAMINE-LIKE (Synaptogenesis)\n","======================================================================\n","\n","    KETAMINE-LIKE TREATMENT:\n","      Regrowth fraction: 50%\n","      Consolidation: 15 epochs\n","      Estimating gradient importance...\n","      Restored 187,749 synapses\n","      Consolidating new synapses...\n","      Final sparsity: 47.5%\n","\n","    POST-TREATMENT EVALUATION:\n","      Clean: 100.0%\n","      Standard: 100.0%\n","      Combined stress: 96.9%\n","      Extreme stress: 84.5%\n","\n","    RELAPSE SIMULATION:\n","      Combined: 96.9% → 97.1% (drop: -0.2%)\n","\n","======================================================================\n","  TREATMENT 2: SSRI-LIKE (Gradual Stabilization)\n","======================================================================\n","\n","    SSRI-LIKE TREATMENT:\n","      Duration: 100 epochs (gradual)\n","      Learning rate: 1e-05 (very low)\n","      Internal stress: 0.5 → 0.0\n","      Note: NO structural changes (fixed sparsity)\n","      SSRI epoch 25/100, stress: 0.379, loss: 1.2153\n","      SSRI epoch 50/100, stress: 0.253, loss: 0.9758\n","      SSRI epoch 75/100, stress: 0.126, loss: 0.7059\n","      SSRI epoch 100/100, stress: 0.000, loss: 0.4658\n","      Final sparsity: 95.0% (unchanged)\n","\n","    POST-TREATMENT EVALUATION:\n","      Clean: 100.0%\n","      Standard: 99.5%\n","      Combined stress: 83.5%\n","      Extreme stress: 44.0%\n","\n","    RELAPSE SIMULATION:\n","      Combined: 83.5% → 72.7% (drop: 10.8%)\n","\n","======================================================================\n","  TREATMENT 3: NEUROSTEROID-LIKE (Tonic Inhibition)\n","======================================================================\n","\n","    NEUROSTEROID-LIKE TREATMENT:\n","      Inhibition strength: 0.7 (30% damping)\n","      Bounded activation (tanh): True\n","      Consolidation: 10 epochs\n","      Note: NO structural changes (fixed sparsity)\n","      Applied tonic inhibition modulation...\n","      Adapting to new activity dynamics...\n","      Final sparsity: 95.0% (unchanged)\n","\n","    POST-TREATMENT EVALUATION (with modulation active):\n","      Clean: 100.0%\n","      Standard: 100.0%\n","      Combined stress: 97.5%\n","      Extreme stress: 42.5%\n","\n","    EVALUATION WITHOUT MODULATION (medication discontinued):\n","      Combined stress: 90.5%\n","      Extreme stress: 58.6%\n","\n","    RELAPSE SIMULATION (with modulation active):\n","      Combined: 97.5% → 93.3% (drop: 4.1%)\n","\n","================================================================================\n","  COMPREHENSIVE COMPARISON: ALL TREATMENTS\n","================================================================================\n","\n","  Treatment                Sparsity    Clean   Standard   Combined    Extreme    Relapse\n","  -------------------------------------------------------------------------------------\n","  Untreated (pruned)          95.0%    50.8%      43.9%      31.8%      28.3%        N/A\n","  Ketamine-like               47.5%   100.0%     100.0%      96.9%      84.5%      -0.2%\n","  SSRI-like                   95.0%   100.0%      99.5%      83.5%      44.0%      10.8%\n","  Neurosteroid-like           95.0%   100.0%     100.0%      97.5%      42.5%       4.1%\n","\n","  STRESS RESILIENCE PROFILE:\n","\n","  Treatment                  None   Moderate     High   Severe    Extreme\n","  ----------------------------------------------------------------------\n","  Untreated (pruned)        43.9%      31.6%    29.9%    28.0%      28.3%\n","  Ketamine-like            100.0%      99.8%    99.0%    96.1%      84.5%\n","  SSRI-like                 99.5%      87.2%    70.3%    58.0%      44.0%\n","  Neurosteroid-like        100.0%      99.9%    89.6%    69.3%      42.5%\n","\n","--------------------------------------------------------------------------------\n","  ANALYSIS\n","--------------------------------------------------------------------------------\n","\n","  1. IMPROVEMENT FROM UNTREATED STATE (Combined Stress):\n","     Ketamine:    31.8% → 96.9% (+65.1%)\n","     SSRI:        31.8% → 83.5% (+51.7%)\n","     Neurosteroid:31.8% → 97.5% (+65.6%)\n","\n","  2. STRUCTURAL VS FUNCTIONAL CHANGES:\n","     Ketamine sparsity:    47.5% (REDUCED from 95%)\n","     SSRI sparsity:        95.0% (UNCHANGED)\n","     Neurosteroid sparsity:95.0% (UNCHANGED)\n","\n","     → Ketamine is the ONLY treatment that adds new connections\n","\n","  3. EXTREME STRESS RESILIENCE (σ=2.5):\n","     Ketamine:    84.5%\n","     SSRI:        44.0%\n","     Neurosteroid:42.5%\n","\n","  4. NEUROSTEROID MEDICATION DEPENDENCE:\n","     Combined ON medication:  97.5%\n","     Combined OFF medication: 90.5%\n","     Extreme ON medication:   42.5%\n","     Extreme OFF medication:  58.6%\n","\n","  5. RELAPSE VULNERABILITY:\n","     Ketamine:    -0.2% drop\n","     SSRI:        10.8% drop\n","     Neurosteroid:4.1% drop\n","\n","--------------------------------------------------------------------------------\n","  CLINICAL INTERPRETATION\n","--------------------------------------------------------------------------------\n","\n","  KEY FINDINGS:\n","\n","  1. MECHANISM MATTERS: Different antidepressants work through distinct routes\n","     - Ketamine REBUILDS: Adds new synapses, restores structural density\n","     - SSRIs REFINE: Strengthen existing pathways via gradual adaptation\n","     - Neurosteroids STABILIZE: Damp hyperexcitability, bound activity range\n","\n","  2. SPEED-DURABILITY TRADEOFF:\n","     - Ketamine: Fast onset, durable changes (new structure persists)\n","     - Neurosteroid: Fast onset, medication-dependent (dynamics reset if stopped)\n","     - SSRI: Slow onset, moderate durability (refined weights persist)\n","\n","  3. TREATMENT SELECTION IMPLICATIONS:\n","     \n","     ┌──────────────────────────────────────┬──────────────────────────────────┐\n","     │ Clinical Scenario                    │ Suggested Mechanism              │\n","     ├──────────────────────────────────────┼──────────────────────────────────┤\n","     │ Severe, treatment-resistant MDD      │ Ketamine (structural repair)     │\n","     │ Postpartum depression, acute crisis  │ Neurosteroid (rapid stabilize)   │\n","     │ Mild-moderate, first-line            │ SSRI (gradual, acceptable)       │\n","     │ Recurrent with high relapse risk     │ Ketamine (durable structure)     │\n","     │ Hyperexcitable/anxious component     │ Neurosteroid (activity damping)  │\n","     └──────────────────────────────────────┴──────────────────────────────────┘\n","\n","  4. COMBINATION THERAPY RATIONALE:\n","     - Ketamine + SSRI: Structural + neuromodulatory benefits\n","     - Neurosteroid + SSRI: Rapid stabilization while waiting for SSRI onset\n","     - Ketamine + Psychotherapy: New synapses + activity-guided consolidation\n","    \n","\n","================================================================================\n","  EXPERIMENT COMPLETE\n","================================================================================\n","\n"]}],"source":["\"\"\"\n","================================================================================\n","MULTI-MECHANISM ANTIDEPRESSANT COMPARISON EXPERIMENT\n","================================================================================\n","\n","This script runs only Experiment 4: comparing three antidepressant mechanisms:\n","1. KETAMINE-LIKE: Gradient-guided synaptogenesis\n","2. SSRI-LIKE: Gradual stabilization without structural changes\n","3. NEUROSTEROID-LIKE: Tonic inhibition enhancement\n","\n","All treatments start from identical pruned (depressed) network states.\n","================================================================================\n","\"\"\"\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","from torch.utils.data import DataLoader, TensorDataset\n","from typing import Dict, Tuple, List\n","import warnings\n","\n","warnings.filterwarnings('ignore', category=UserWarning)\n","\n","# ============================================================================\n","# REPRODUCIBILITY\n","# ============================================================================\n","SEED = 42\n","torch.manual_seed(SEED)\n","np.random.seed(SEED)\n","DEVICE = torch.device('cpu')\n","\n","# ============================================================================\n","# CONFIGURATION - Fixed version with proper syntax\n","# ============================================================================\n","CONFIG = {\n","    # Data generation\n","    'n_train': 12000,\n","    'n_test': 4000,\n","    'n_clean_test': 2000,\n","    'data_noise': 0.8,\n","    'batch_size': 128,\n","\n","    # Network architecture\n","    'hidden_dims': [512, 512, 256],\n","    'input_dim': 2,\n","    'output_dim': 4,\n","\n","    # Training hyperparameters\n","    'baseline_epochs': 20,\n","    'baseline_lr': 0.001,\n","    'finetune_epochs': 15,\n","    'finetune_lr': 0.0005,\n","\n","    # Pruning parameters\n","    'prune_sparsity': 0.95,\n","\n","    # Regrowth parameters\n","    'regrow_fraction': 0.5,\n","    'regrow_init_scale': 0.03,\n","    'gradient_accumulation_batches': 30,\n","\n","    # Stress levels for evaluation\n","    'extended_stress_levels': {\n","        'none': 0.0,\n","        'moderate': 0.5,\n","        'high': 1.0,\n","        'severe': 1.5,\n","        'extreme': 2.5\n","    },\n","\n","    # ========================================================================\n","    # MONOAMINERGIC (SSRI-LIKE) TREATMENT PARAMETERS\n","    # ========================================================================\n","    # Biological rationale: SSRIs increase synaptic serotonin, leading to\n","    # gradual receptor adaptations over weeks. No rapid synaptogenesis.\n","    # Network analog: Fixed sparsity, very low LR, gradual noise reduction.\n","    'monoaminergic_epochs': 100,\n","    'monoaminergic_lr': 1e-5,\n","    'monoaminergic_initial_stress': 0.5,\n","\n","    # ========================================================================\n","    # NEUROSTEROID (GABAergic) TREATMENT PARAMETERS\n","    # ========================================================================\n","    # Biological rationale: Neurosteroids enhance tonic GABA inhibition,\n","    # reducing network excitability rapidly (days, not weeks).\n","    # Network analog: Global activation damping, bounded activations.\n","    'neurosteroid_inhibition_strength': 0.7,\n","    'neurosteroid_use_tanh': True,\n","    'neurosteroid_consolidation_epochs': 10,\n","\n","    # ========================================================================\n","    # MULTI-MECHANISM COMPARISON PARAMETERS\n","    # ========================================================================\n","    'comparison_ketamine_regrow': 0.5,\n","    'comparison_ketamine_epochs': 15,\n","    'comparison_ssri_epochs': 100,\n","    'comparison_neurosteroid_strength': 0.7,\n","    'comparison_neurosteroid_epochs': 10,\n","}\n","\n","\n","# ============================================================================\n","# DATA GENERATION\n","# ============================================================================\n","def generate_blobs(\n","    n_samples: int = 10000,\n","    noise: float = 0.8,\n","    seed: int = None\n",") -> Tuple[torch.Tensor, torch.Tensor]:\n","    \"\"\"Generate 4-class Gaussian blob classification data.\"\"\"\n","    if seed is not None:\n","        rng = np.random.RandomState(seed)\n","    else:\n","        rng = np.random.RandomState()\n","\n","    centers = np.array([[-3, -3], [3, 3], [-3, 3], [3, -3]])\n","    labels = rng.randint(0, 4, n_samples)\n","    data = centers[labels] + rng.randn(n_samples, 2) * noise\n","\n","    return (\n","        torch.tensor(data, dtype=torch.float32),\n","        torch.tensor(labels, dtype=torch.long)\n","    )\n","\n","\n","def create_data_loaders() -> Tuple[DataLoader, DataLoader, DataLoader]:\n","    \"\"\"Create train, test, and clean test data loaders.\"\"\"\n","    train_data, train_labels = generate_blobs(CONFIG['n_train'], noise=CONFIG['data_noise'], seed=100)\n","    test_data, test_labels = generate_blobs(CONFIG['n_test'], noise=CONFIG['data_noise'], seed=200)\n","    clean_test_data, clean_test_labels = generate_blobs(CONFIG['n_clean_test'], noise=0.0, seed=300)\n","\n","    train_loader = DataLoader(TensorDataset(train_data, train_labels), batch_size=CONFIG['batch_size'], shuffle=True)\n","    test_loader = DataLoader(TensorDataset(test_data, test_labels), batch_size=1000)\n","    clean_test_loader = DataLoader(TensorDataset(clean_test_data, clean_test_labels), batch_size=1000)\n","\n","    return train_loader, test_loader, clean_test_loader\n","\n","\n","train_loader, test_loader, clean_test_loader = create_data_loaders()\n","\n","\n","# ============================================================================\n","# NETWORK ARCHITECTURE\n","# ============================================================================\n","class StressAwareNetwork(nn.Module):\n","    \"\"\"\n","    Feed-forward network with internal noise injection and GABAergic modulation.\n","\n","    Supports three modulation mechanisms:\n","    - stress_level: Internal noise (neuromodulatory disruption)\n","    - inhibition_strength: Multiplicative damping (tonic GABA inhibition)\n","    - use_tanh: Bounded activation (shunting inhibition)\n","    \"\"\"\n","\n","    def __init__(self, hidden_dims: List[int] = None):\n","        super().__init__()\n","        if hidden_dims is None:\n","            hidden_dims = CONFIG['hidden_dims']\n","\n","        self.fc1 = nn.Linear(CONFIG['input_dim'], hidden_dims[0])\n","        self.fc2 = nn.Linear(hidden_dims[0], hidden_dims[1])\n","        self.fc3 = nn.Linear(hidden_dims[1], hidden_dims[2])\n","        self.fc4 = nn.Linear(hidden_dims[2], CONFIG['output_dim'])\n","\n","        self.relu = nn.ReLU()\n","        self.tanh = nn.Tanh()\n","\n","        # Modulation parameters\n","        self.stress_level = 0.0           # Internal noise magnitude\n","        self.inhibition_strength = 1.0    # Multiplicative damping (1.0 = none)\n","        self.use_tanh = False             # Use bounded activation\n","\n","        self.weight_layers = ['fc1', 'fc2', 'fc3', 'fc4']\n","\n","    def set_stress(self, level: float):\n","        \"\"\"Set internal noise level for stress simulation.\"\"\"\n","        self.stress_level = level\n","\n","    def set_inhibition(self, strength: float, use_tanh: bool = False):\n","        \"\"\"Set GABAergic tonic inhibition parameters.\"\"\"\n","        self.inhibition_strength = strength\n","        self.use_tanh = use_tanh\n","\n","    def reduce_stress_gradually(self, epoch: int, total_epochs: int,\n","                                 initial_stress: float = 0.5, final_stress: float = 0.0):\n","        \"\"\"Linearly reduce internal stress over epochs (SSRI-like).\"\"\"\n","        progress = epoch / max(total_epochs - 1, 1)\n","        self.stress_level = initial_stress + progress * (final_stress - initial_stress)\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        \"\"\"Forward pass with noise injection and inhibitory modulation.\"\"\"\n","        activation = self.tanh if self.use_tanh else self.relu\n","\n","        # Layer 1\n","        h = activation(self.fc1(x))\n","        if self.stress_level > 0:\n","            h = h + torch.randn_like(h) * self.stress_level\n","        h = h * self.inhibition_strength\n","\n","        # Layer 2\n","        h = activation(self.fc2(h))\n","        if self.stress_level > 0:\n","            h = h + torch.randn_like(h) * self.stress_level\n","        h = h * self.inhibition_strength\n","\n","        # Layer 3\n","        h = activation(self.fc3(h))\n","        if self.stress_level > 0:\n","            h = h + torch.randn_like(h) * self.stress_level\n","        h = h * self.inhibition_strength\n","\n","        # Output layer (no modulation)\n","        return self.fc4(h)\n","\n","    def count_parameters(self) -> Tuple[int, int]:\n","        \"\"\"Count total and non-zero parameters.\"\"\"\n","        total = sum(p.numel() for p in self.parameters())\n","        nonzero = sum((p != 0).sum().item() for p in self.parameters())\n","        return total, nonzero\n","\n","\n","# ============================================================================\n","# PRUNING MANAGER\n","# ============================================================================\n","class PruningManager:\n","    \"\"\"Manages structured pruning and gradient-guided regrowth.\"\"\"\n","\n","    def __init__(self, model: StressAwareNetwork):\n","        self.model = model\n","        self.masks = {}\n","        self.gradient_buffer = {}\n","\n","        for name, param in model.named_parameters():\n","            if 'weight' in name and param.dim() >= 2:\n","                self.masks[name] = torch.ones_like(param, dtype=torch.float32)\n","                self.gradient_buffer[name] = torch.zeros_like(param)\n","\n","    def prune_by_magnitude(self, sparsity: float, per_layer: bool = True) -> Dict[str, Dict]:\n","        \"\"\"Prune weights by magnitude.\"\"\"\n","        stats = {}\n","\n","        for name, param in self.model.named_parameters():\n","            if name in self.masks:\n","                weights = param.data.abs()\n","                threshold = torch.quantile(weights.flatten(), sparsity)\n","                self.masks[name] = (weights >= threshold).float()\n","                param.data *= self.masks[name]\n","\n","                kept = self.masks[name].sum().item()\n","                total = self.masks[name].numel()\n","                stats[name] = {'kept': int(kept), 'total': total, 'actual_sparsity': 1 - kept/total}\n","\n","        return stats\n","\n","    def _accumulate_gradients(self, num_batches: int = 30):\n","        \"\"\"Accumulate gradient magnitudes at pruned positions.\"\"\"\n","        model = self.model\n","        loss_fn = nn.CrossEntropyLoss()\n","\n","        for name in self.gradient_buffer:\n","            self.gradient_buffer[name].zero_()\n","\n","        model.train()\n","        original_stress = model.stress_level\n","        model.set_stress(0.0)\n","\n","        batch_count = 0\n","        for x, y in train_loader:\n","            if batch_count >= num_batches:\n","                break\n","            x, y = x.to(DEVICE), y.to(DEVICE)\n","            loss = loss_fn(model(x), y)\n","            loss.backward()\n","\n","            with torch.no_grad():\n","                for name, param in model.named_parameters():\n","                    if name in self.masks:\n","                        pruned_mask = (self.masks[name] == 0).float()\n","                        self.gradient_buffer[name] += param.grad.abs() * pruned_mask\n","            model.zero_grad()\n","            batch_count += 1\n","\n","        model.set_stress(original_stress)\n","\n","    def gradient_guided_regrow(self, regrow_fraction: float,\n","                                init_scale: float = None) -> Dict[str, Dict]:\n","        \"\"\"Regrow pruned connections based on gradient importance.\"\"\"\n","        if init_scale is None:\n","            init_scale = CONFIG['regrow_init_scale']\n","\n","        self._accumulate_gradients(num_batches=CONFIG['gradient_accumulation_batches'])\n","\n","        stats = {}\n","        for name, param in self.model.named_parameters():\n","            if name not in self.masks:\n","                continue\n","\n","            mask = self.masks[name]\n","            pruned_positions = (mask == 0)\n","            num_pruned = pruned_positions.sum().item()\n","\n","            if num_pruned == 0:\n","                stats[name] = {'regrown': 0, 'still_pruned': 0}\n","                continue\n","\n","            gradient_scores = self.gradient_buffer[name][pruned_positions]\n","            num_regrow = max(1, int(regrow_fraction * num_pruned))\n","            num_regrow = min(num_regrow, gradient_scores.numel())\n","\n","            _, top_indices = torch.topk(gradient_scores.flatten(), num_regrow)\n","            flat_pruned_indices = torch.where(pruned_positions.flatten())[0]\n","            regrow_flat_indices = flat_pruned_indices[top_indices]\n","\n","            flat_mask = mask.flatten()\n","            flat_param = param.data.flatten()\n","            flat_mask[regrow_flat_indices] = 1.0\n","            flat_param[regrow_flat_indices] = torch.randn(num_regrow) * init_scale\n","\n","            self.masks[name] = flat_mask.view_as(mask)\n","            param.data = flat_param.view_as(param)\n","\n","            stats[name] = {'regrown': num_regrow, 'still_pruned': int(num_pruned - num_regrow)}\n","\n","        return stats\n","\n","    def apply_masks(self):\n","        \"\"\"Re-apply masks to maintain sparsity.\"\"\"\n","        with torch.no_grad():\n","            for name, param in self.model.named_parameters():\n","                if name in self.masks:\n","                    param.data *= self.masks[name]\n","\n","    def get_sparsity(self) -> float:\n","        \"\"\"Calculate overall network sparsity.\"\"\"\n","        total = sum(m.numel() for m in self.masks.values())\n","        zeros = sum((m == 0).sum().item() for m in self.masks.values())\n","        return zeros / total if total > 0 else 0.0\n","\n","\n","# ============================================================================\n","# TRAINING FUNCTIONS\n","# ============================================================================\n","def train(model: StressAwareNetwork, epochs: int = 15, lr: float = 0.001,\n","          pruning_manager: PruningManager = None, verbose: bool = False) -> List[float]:\n","    \"\"\"Standard training loop.\"\"\"\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    loss_fn = nn.CrossEntropyLoss()\n","    losses = []\n","\n","    original_stress = model.stress_level\n","    model.set_stress(0.0)\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        epoch_loss = 0.0\n","        for x, y in train_loader:\n","            x, y = x.to(DEVICE), y.to(DEVICE)\n","            optimizer.zero_grad()\n","            loss = loss_fn(model(x), y)\n","            loss.backward()\n","            optimizer.step()\n","            if pruning_manager:\n","                pruning_manager.apply_masks()\n","            epoch_loss += loss.item()\n","        losses.append(epoch_loss / len(train_loader))\n","        if verbose:\n","            print(f\"      Epoch {epoch+1}/{epochs}, Loss: {losses[-1]:.4f}\")\n","\n","    model.set_stress(original_stress)\n","    return losses\n","\n","\n","def train_with_stress_schedule(model: StressAwareNetwork, epochs: int, lr: float,\n","                                initial_stress: float, final_stress: float = 0.0,\n","                                pruning_manager: PruningManager = None,\n","                                verbose: bool = False, print_interval: int = 20) -> List[float]:\n","    \"\"\"Train with gradually reducing internal stress (SSRI-like).\"\"\"\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    loss_fn = nn.CrossEntropyLoss()\n","    losses = []\n","\n","    for epoch in range(epochs):\n","        model.reduce_stress_gradually(epoch, epochs, initial_stress, final_stress)\n","        model.train()\n","        epoch_loss = 0.0\n","\n","        for x, y in train_loader:\n","            x, y = x.to(DEVICE), y.to(DEVICE)\n","            optimizer.zero_grad()\n","            loss = loss_fn(model(x), y)\n","            loss.backward()\n","            optimizer.step()\n","            if pruning_manager:\n","                pruning_manager.apply_masks()\n","            epoch_loss += loss.item()\n","\n","        losses.append(epoch_loss / len(train_loader))\n","        if verbose and (epoch + 1) % print_interval == 0:\n","            print(f\"      SSRI epoch {epoch+1}/{epochs}, stress: {model.stress_level:.3f}, loss: {losses[-1]:.4f}\")\n","\n","    model.set_stress(0.0)\n","    return losses\n","\n","\n","# ============================================================================\n","# EVALUATION FUNCTIONS\n","# ============================================================================\n","def evaluate(model: StressAwareNetwork, loader: DataLoader,\n","             input_noise: float = 0.0, internal_stress: float = 0.0) -> float:\n","    \"\"\"Evaluate model accuracy.\"\"\"\n","    model.eval()\n","    model.set_stress(internal_stress)\n","    correct, total = 0, 0\n","\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x, y = x.to(DEVICE), y.to(DEVICE)\n","            if input_noise > 0:\n","                x = x + torch.randn_like(x) * input_noise\n","            correct += (model(x).argmax(dim=1) == y).sum().item()\n","            total += y.size(0)\n","\n","    model.set_stress(0.0)\n","    return 100.0 * correct / total\n","\n","\n","def evaluate_with_neurosteroid(model: StressAwareNetwork, loader: DataLoader,\n","                                input_noise: float = 0.0, internal_stress: float = 0.0) -> float:\n","    \"\"\"Evaluate with neurosteroid modulation ACTIVE (inhibition settings preserved).\"\"\"\n","    model.eval()\n","    model.set_stress(internal_stress)\n","    correct, total = 0, 0\n","\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x, y = x.to(DEVICE), y.to(DEVICE)\n","            if input_noise > 0:\n","                x = x + torch.randn_like(x) * input_noise\n","            correct += (model(x).argmax(dim=1) == y).sum().item()\n","            total += y.size(0)\n","\n","    model.set_stress(0.0)\n","    return 100.0 * correct / total\n","\n","\n","# ============================================================================\n","# TREATMENT PROTOCOLS\n","# ============================================================================\n","def ketamine_treatment(model: StressAwareNetwork, pruning_mgr: PruningManager,\n","                       regrow_fraction: float = None, consolidation_epochs: int = None,\n","                       verbose: bool = True) -> Dict:\n","    \"\"\"\n","    KETAMINE-LIKE TREATMENT: Gradient-guided synaptogenesis.\n","\n","    Biological model:\n","    - NMDA antagonism → BDNF release → mTOR activation → new spine formation\n","    - Activity-dependent targeting of new synapses\n","    - Brief consolidation to strengthen useful connections\n","\n","    Key feature: ADDS NEW SYNAPSES (reduces sparsity)\n","    \"\"\"\n","    if regrow_fraction is None:\n","        regrow_fraction = CONFIG['comparison_ketamine_regrow']\n","    if consolidation_epochs is None:\n","        consolidation_epochs = CONFIG['comparison_ketamine_epochs']\n","\n","    if verbose:\n","        print(f\"\\n    KETAMINE-LIKE TREATMENT:\")\n","        print(f\"      Regrowth fraction: {regrow_fraction*100:.0f}%\")\n","        print(f\"      Consolidation: {consolidation_epochs} epochs\")\n","        print(f\"      Estimating gradient importance...\")\n","\n","    regrow_stats = pruning_mgr.gradient_guided_regrow(regrow_fraction=regrow_fraction)\n","    total_regrown = sum(s['regrown'] for s in regrow_stats.values())\n","\n","    if verbose:\n","        print(f\"      Restored {total_regrown:,} synapses\")\n","        print(f\"      Consolidating new synapses...\")\n","\n","    consolidation_losses = train(model, epochs=consolidation_epochs,\n","                                  lr=CONFIG['finetune_lr'], pruning_manager=pruning_mgr)\n","\n","    final_sparsity = pruning_mgr.get_sparsity()\n","    if verbose:\n","        print(f\"      Final sparsity: {final_sparsity*100:.1f}%\")\n","\n","    return {'regrow_stats': regrow_stats, 'final_sparsity': final_sparsity}\n","\n","\n","def ssri_treatment(model: StressAwareNetwork, pruning_mgr: PruningManager,\n","                   epochs: int = None, learning_rate: float = None,\n","                   initial_stress: float = None, verbose: bool = True,\n","                   print_interval: int = 25) -> Dict:\n","    \"\"\"\n","    SSRI-LIKE TREATMENT: Gradual stabilization without structural changes.\n","\n","    Biological model:\n","    - Increased synaptic serotonin → gradual receptor adaptations\n","    - 5-HT1A autoreceptor desensitization over weeks\n","    - Improved signal-to-noise in existing circuits\n","\n","    Key feature: NO NEW SYNAPSES (sparsity unchanged)\n","    \"\"\"\n","    if epochs is None:\n","        epochs = CONFIG['monoaminergic_epochs']\n","    if learning_rate is None:\n","        learning_rate = CONFIG['monoaminergic_lr']\n","    if initial_stress is None:\n","        initial_stress = CONFIG['monoaminergic_initial_stress']\n","\n","    if verbose:\n","        print(f\"\\n    SSRI-LIKE TREATMENT:\")\n","        print(f\"      Duration: {epochs} epochs (gradual)\")\n","        print(f\"      Learning rate: {learning_rate} (very low)\")\n","        print(f\"      Internal stress: {initial_stress} → 0.0\")\n","        print(f\"      Note: NO structural changes (fixed sparsity)\")\n","\n","    initial_sparsity = pruning_mgr.get_sparsity()\n","\n","    losses = train_with_stress_schedule(model, epochs=epochs, lr=learning_rate,\n","                                         initial_stress=initial_stress, final_stress=0.0,\n","                                         pruning_manager=pruning_mgr, verbose=verbose,\n","                                         print_interval=print_interval)\n","\n","    final_sparsity = pruning_mgr.get_sparsity()\n","    if verbose:\n","        print(f\"      Final sparsity: {final_sparsity*100:.1f}% (unchanged)\")\n","\n","    return {'final_sparsity': final_sparsity, 'training_losses': losses}\n","\n","\n","def neurosteroid_treatment(model: StressAwareNetwork, pruning_mgr: PruningManager,\n","                           inhibition_strength: float = None, use_tanh: bool = None,\n","                           consolidation_epochs: int = None, verbose: bool = True) -> Dict:\n","    \"\"\"\n","    NEUROSTEROID-LIKE TREATMENT: Enhanced tonic inhibition.\n","\n","    Biological model:\n","    - Enhanced extrasynaptic GABA-A receptor activation\n","    - Tonic (sustained) inhibition reduces network excitability\n","    - Rapid onset (days, not weeks)\n","\n","    Key features:\n","    - NO NEW SYNAPSES (sparsity unchanged)\n","    - Works by DAMPING activity rather than building structure\n","    - Medication-dependent (effects reverse when stopped)\n","    \"\"\"\n","    if inhibition_strength is None:\n","        inhibition_strength = CONFIG['neurosteroid_inhibition_strength']\n","    if use_tanh is None:\n","        use_tanh = CONFIG['neurosteroid_use_tanh']\n","    if consolidation_epochs is None:\n","        consolidation_epochs = CONFIG['neurosteroid_consolidation_epochs']\n","\n","    if verbose:\n","        print(f\"\\n    NEUROSTEROID-LIKE TREATMENT:\")\n","        print(f\"      Inhibition strength: {inhibition_strength} ({(1-inhibition_strength)*100:.0f}% damping)\")\n","        print(f\"      Bounded activation (tanh): {use_tanh}\")\n","        print(f\"      Consolidation: {consolidation_epochs} epochs\")\n","        print(f\"      Note: NO structural changes (fixed sparsity)\")\n","\n","    # Apply tonic inhibition modulation\n","    model.set_inhibition(inhibition_strength, use_tanh)\n","    if verbose:\n","        print(f\"      Applied tonic inhibition modulation...\")\n","        print(f\"      Adapting to new activity dynamics...\")\n","\n","    consolidation_losses = train(model, epochs=consolidation_epochs,\n","                                  lr=CONFIG['finetune_lr'], pruning_manager=pruning_mgr)\n","\n","    final_sparsity = pruning_mgr.get_sparsity()\n","    if verbose:\n","        print(f\"      Final sparsity: {final_sparsity*100:.1f}% (unchanged)\")\n","\n","    return {'final_sparsity': final_sparsity, 'inhibition_strength': inhibition_strength,\n","            'use_tanh': use_tanh}\n","\n","\n","# ============================================================================\n","# MAIN EXPERIMENT\n","# ============================================================================\n","def run_multi_mechanism_experiment() -> Dict[str, Dict]:\n","    \"\"\"\n","    Compare ketamine, SSRI, and neurosteroid treatment mechanisms.\n","\n","    All treatments start from identical 95% sparse (depressed) networks.\n","    \"\"\"\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"  MULTI-MECHANISM ANTIDEPRESSANT COMPARISON EXPERIMENT\")\n","    print(\"=\"*80)\n","\n","    print(\"\"\"\n","  COMPARING THREE ANTIDEPRESSANT MECHANISMS:\n","\n","  ┌─────────────────┬─────────────────────────────────────────────────────────┐\n","  │ Mechanism       │ Key Feature                                             │\n","  ├─────────────────┼─────────────────────────────────────────────────────────┤\n","  │ Ketamine        │ Gradient-guided synaptogenesis (↑ density)              │\n","  │ SSRI            │ Gradual noise reduction (stabilizes existing weights)   │\n","  │ Neurosteroid    │ Tonic inhibition (damps activity, bounds firing)        │\n","  └─────────────────┴─────────────────────────────────────────────────────────┘\n","\n","  All treatments start from identical 95% sparse (depressed) networks.\n","    \"\"\")\n","\n","    # ========================================================================\n","    # PREPARE BASE PRUNED MODEL\n","    # ========================================================================\n","    print(\"-\"*70)\n","    print(\"  Preparing shared pruned baseline...\")\n","    print(\"-\"*70)\n","\n","    base_model = StressAwareNetwork().to(DEVICE)\n","    print(f\"  Training full network ({CONFIG['baseline_epochs']} epochs)...\")\n","    train(base_model, epochs=CONFIG['baseline_epochs'], lr=CONFIG['baseline_lr'])\n","\n","    base_pruning_mgr = PruningManager(base_model)\n","    base_pruning_mgr.prune_by_magnitude(sparsity=CONFIG['prune_sparsity'], per_layer=True)\n","\n","    initial_sparsity = base_pruning_mgr.get_sparsity()\n","    print(f\"  Pruned to {initial_sparsity*100:.1f}% sparse\")\n","\n","    # Evaluate untreated state\n","    print(\"\\n  UNTREATED PRUNED STATE:\")\n","    untreated_results = {'sparsity': initial_sparsity * 100}\n","    untreated_results['clean'] = evaluate(base_model, clean_test_loader, 0.0, 0.0)\n","    untreated_results['standard'] = evaluate(base_model, test_loader, 0.0, 0.0)\n","    for stress_name, stress_level in CONFIG['extended_stress_levels'].items():\n","        untreated_results[f'stress_{stress_name}'] = evaluate(base_model, test_loader, 0.0, stress_level)\n","    untreated_results['combined'] = evaluate(base_model, test_loader, 1.0, 0.5)\n","\n","    print(f\"    Clean: {untreated_results['clean']:.1f}%\")\n","    print(f\"    Standard: {untreated_results['standard']:.1f}%\")\n","    print(f\"    Combined stress: {untreated_results['combined']:.1f}%\")\n","    print(f\"    Extreme stress: {untreated_results['stress_extreme']:.1f}%\")\n","\n","    # Save state for cloning\n","    base_state_dict = {k: v.clone() for k, v in base_model.state_dict().items()}\n","    base_masks = {k: v.clone() for k, v in base_pruning_mgr.masks.items()}\n","\n","    results = {'untreated': untreated_results}\n","\n","    # ========================================================================\n","    # TREATMENT 1: KETAMINE-LIKE\n","    # ========================================================================\n","    print(\"\\n\" + \"=\"*70)\n","    print(\"  TREATMENT 1: KETAMINE-LIKE (Synaptogenesis)\")\n","    print(\"=\"*70)\n","\n","    ketamine_model = StressAwareNetwork().to(DEVICE)\n","    ketamine_model.load_state_dict(base_state_dict)\n","    ketamine_mgr = PruningManager(ketamine_model)\n","    ketamine_mgr.masks = {k: v.clone() for k, v in base_masks.items()}\n","    ketamine_mgr.apply_masks()\n","\n","    ketamine_stats = ketamine_treatment(ketamine_model, ketamine_mgr,\n","                                         regrow_fraction=CONFIG['comparison_ketamine_regrow'],\n","                                         consolidation_epochs=CONFIG['comparison_ketamine_epochs'])\n","\n","    print(\"\\n    POST-TREATMENT EVALUATION:\")\n","    ketamine_results = {'sparsity': ketamine_mgr.get_sparsity() * 100}\n","    ketamine_results['clean'] = evaluate(ketamine_model, clean_test_loader, 0.0, 0.0)\n","    ketamine_results['standard'] = evaluate(ketamine_model, test_loader, 0.0, 0.0)\n","    for stress_name, stress_level in CONFIG['extended_stress_levels'].items():\n","        ketamine_results[f'stress_{stress_name}'] = evaluate(ketamine_model, test_loader, 0.0, stress_level)\n","    ketamine_results['combined'] = evaluate(ketamine_model, test_loader, 1.0, 0.5)\n","\n","    print(f\"      Clean: {ketamine_results['clean']:.1f}%\")\n","    print(f\"      Standard: {ketamine_results['standard']:.1f}%\")\n","    print(f\"      Combined stress: {ketamine_results['combined']:.1f}%\")\n","    print(f\"      Extreme stress: {ketamine_results['stress_extreme']:.1f}%\")\n","\n","    # Relapse simulation\n","    print(\"\\n    RELAPSE SIMULATION:\")\n","    pre_relapse = ketamine_results['combined']\n","    pre_sparsity = ketamine_mgr.get_sparsity()\n","    target_sparsity = min(pre_sparsity + (1 - pre_sparsity) * 0.40, 0.99)\n","    ketamine_mgr.prune_by_magnitude(sparsity=target_sparsity, per_layer=True)\n","    ketamine_mgr.apply_masks()\n","    post_relapse = evaluate(ketamine_model, test_loader, 1.0, 0.5)\n","    ketamine_results['relapse_drop'] = pre_relapse - post_relapse\n","    print(f\"      Combined: {pre_relapse:.1f}% → {post_relapse:.1f}% (drop: {ketamine_results['relapse_drop']:.1f}%)\")\n","\n","    results['ketamine'] = ketamine_results\n","\n","    # ========================================================================\n","    # TREATMENT 2: SSRI-LIKE\n","    # ========================================================================\n","    print(\"\\n\" + \"=\"*70)\n","    print(\"  TREATMENT 2: SSRI-LIKE (Gradual Stabilization)\")\n","    print(\"=\"*70)\n","\n","    ssri_model = StressAwareNetwork().to(DEVICE)\n","    ssri_model.load_state_dict(base_state_dict)\n","    ssri_mgr = PruningManager(ssri_model)\n","    ssri_mgr.masks = {k: v.clone() for k, v in base_masks.items()}\n","    ssri_mgr.apply_masks()\n","\n","    ssri_stats = ssri_treatment(ssri_model, ssri_mgr,\n","                                 epochs=CONFIG['comparison_ssri_epochs'],\n","                                 learning_rate=CONFIG['monoaminergic_lr'],\n","                                 initial_stress=CONFIG['monoaminergic_initial_stress'],\n","                                 print_interval=25)\n","\n","    print(\"\\n    POST-TREATMENT EVALUATION:\")\n","    ssri_results = {'sparsity': ssri_mgr.get_sparsity() * 100}\n","    ssri_results['clean'] = evaluate(ssri_model, clean_test_loader, 0.0, 0.0)\n","    ssri_results['standard'] = evaluate(ssri_model, test_loader, 0.0, 0.0)\n","    for stress_name, stress_level in CONFIG['extended_stress_levels'].items():\n","        ssri_results[f'stress_{stress_name}'] = evaluate(ssri_model, test_loader, 0.0, stress_level)\n","    ssri_results['combined'] = evaluate(ssri_model, test_loader, 1.0, 0.5)\n","\n","    print(f\"      Clean: {ssri_results['clean']:.1f}%\")\n","    print(f\"      Standard: {ssri_results['standard']:.1f}%\")\n","    print(f\"      Combined stress: {ssri_results['combined']:.1f}%\")\n","    print(f\"      Extreme stress: {ssri_results['stress_extreme']:.1f}%\")\n","\n","    # Relapse simulation\n","    print(\"\\n    RELAPSE SIMULATION:\")\n","    pre_relapse = ssri_results['combined']\n","    pre_sparsity = ssri_mgr.get_sparsity()\n","    target_sparsity = min(pre_sparsity + (1 - pre_sparsity) * 0.40, 0.99)\n","    ssri_mgr.prune_by_magnitude(sparsity=target_sparsity, per_layer=True)\n","    ssri_mgr.apply_masks()\n","    post_relapse = evaluate(ssri_model, test_loader, 1.0, 0.5)\n","    ssri_results['relapse_drop'] = pre_relapse - post_relapse\n","    print(f\"      Combined: {pre_relapse:.1f}% → {post_relapse:.1f}% (drop: {ssri_results['relapse_drop']:.1f}%)\")\n","\n","    results['ssri'] = ssri_results\n","\n","    # ========================================================================\n","    # TREATMENT 3: NEUROSTEROID-LIKE\n","    # ========================================================================\n","    print(\"\\n\" + \"=\"*70)\n","    print(\"  TREATMENT 3: NEUROSTEROID-LIKE (Tonic Inhibition)\")\n","    print(\"=\"*70)\n","\n","    neuro_model = StressAwareNetwork().to(DEVICE)\n","    neuro_model.load_state_dict(base_state_dict)\n","    neuro_mgr = PruningManager(neuro_model)\n","    neuro_mgr.masks = {k: v.clone() for k, v in base_masks.items()}\n","    neuro_mgr.apply_masks()\n","\n","    neuro_stats = neurosteroid_treatment(neuro_model, neuro_mgr,\n","                                          inhibition_strength=CONFIG['neurosteroid_inhibition_strength'],\n","                                          use_tanh=CONFIG['neurosteroid_use_tanh'],\n","                                          consolidation_epochs=CONFIG['neurosteroid_consolidation_epochs'])\n","\n","    # Evaluate WITH modulation active (patient on medication)\n","    print(\"\\n    POST-TREATMENT EVALUATION (with modulation active):\")\n","    neuro_results = {'sparsity': neuro_mgr.get_sparsity() * 100}\n","    neuro_results['clean'] = evaluate_with_neurosteroid(neuro_model, clean_test_loader, 0.0, 0.0)\n","    neuro_results['standard'] = evaluate_with_neurosteroid(neuro_model, test_loader, 0.0, 0.0)\n","    for stress_name, stress_level in CONFIG['extended_stress_levels'].items():\n","        neuro_results[f'stress_{stress_name}'] = evaluate_with_neurosteroid(neuro_model, test_loader, 0.0, stress_level)\n","    neuro_results['combined'] = evaluate_with_neurosteroid(neuro_model, test_loader, 1.0, 0.5)\n","\n","    print(f\"      Clean: {neuro_results['clean']:.1f}%\")\n","    print(f\"      Standard: {neuro_results['standard']:.1f}%\")\n","    print(f\"      Combined stress: {neuro_results['combined']:.1f}%\")\n","    print(f\"      Extreme stress: {neuro_results['stress_extreme']:.1f}%\")\n","\n","    # Test WITHOUT modulation (medication discontinued)\n","    print(\"\\n    EVALUATION WITHOUT MODULATION (medication discontinued):\")\n","    neuro_model.set_inhibition(1.0, False)\n","    off_med_combined = evaluate(neuro_model, test_loader, 1.0, 0.5)\n","    off_med_extreme = evaluate(neuro_model, test_loader, 0.0, 2.5)\n","    print(f\"      Combined stress: {off_med_combined:.1f}%\")\n","    print(f\"      Extreme stress: {off_med_extreme:.1f}%\")\n","    neuro_results['off_medication_combined'] = off_med_combined\n","    neuro_results['off_medication_extreme'] = off_med_extreme\n","\n","    # Restore modulation for relapse test\n","    neuro_model.set_inhibition(CONFIG['neurosteroid_inhibition_strength'],\n","                                CONFIG['neurosteroid_use_tanh'])\n","\n","    # Relapse simulation\n","    print(\"\\n    RELAPSE SIMULATION (with modulation active):\")\n","    pre_relapse = neuro_results['combined']\n","    pre_sparsity = neuro_mgr.get_sparsity()\n","    target_sparsity = min(pre_sparsity + (1 - pre_sparsity) * 0.40, 0.99)\n","    neuro_mgr.prune_by_magnitude(sparsity=target_sparsity, per_layer=True)\n","    neuro_mgr.apply_masks()\n","    post_relapse = evaluate_with_neurosteroid(neuro_model, test_loader, 1.0, 0.5)\n","    neuro_results['relapse_drop'] = pre_relapse - post_relapse\n","    print(f\"      Combined: {pre_relapse:.1f}% → {post_relapse:.1f}% (drop: {neuro_results['relapse_drop']:.1f}%)\")\n","\n","    results['neurosteroid'] = neuro_results\n","\n","    # ========================================================================\n","    # COMPREHENSIVE COMPARISON\n","    # ========================================================================\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"  COMPREHENSIVE COMPARISON: ALL TREATMENTS\")\n","    print(\"=\"*80)\n","\n","    treatments = ['untreated', 'ketamine', 'ssri', 'neurosteroid']\n","    labels = {'untreated': 'Untreated (pruned)', 'ketamine': 'Ketamine-like',\n","              'ssri': 'SSRI-like', 'neurosteroid': 'Neurosteroid-like'}\n","\n","    print(f\"\\n  {'Treatment':<22} {'Sparsity':>10} {'Clean':>8} {'Standard':>10} \"\n","          f\"{'Combined':>10} {'Extreme':>10} {'Relapse':>10}\")\n","    print(\"  \" + \"-\"*85)\n","\n","    for t in treatments:\n","        r = results[t]\n","        relapse = r.get('relapse_drop', 'N/A')\n","        relapse_str = f\"{relapse:.1f}%\" if isinstance(relapse, float) else relapse\n","        print(f\"  {labels[t]:<22} {r['sparsity']:>9.1f}% {r['clean']:>7.1f}% \"\n","              f\"{r['standard']:>9.1f}% {r['combined']:>9.1f}% \"\n","              f\"{r['stress_extreme']:>9.1f}% {relapse_str:>10}\")\n","\n","    # Stress resilience profile\n","    print(\"\\n  STRESS RESILIENCE PROFILE:\")\n","    print(f\"\\n  {'Treatment':<22} {'None':>8} {'Moderate':>10} {'High':>8} {'Severe':>8} {'Extreme':>10}\")\n","    print(\"  \" + \"-\"*70)\n","\n","    for t in treatments:\n","        r = results[t]\n","        print(f\"  {labels[t]:<22} {r['stress_none']:>7.1f}% {r['stress_moderate']:>9.1f}% \"\n","              f\"{r['stress_high']:>7.1f}% {r['stress_severe']:>7.1f}% {r['stress_extreme']:>9.1f}%\")\n","\n","    # ========================================================================\n","    # ANALYSIS\n","    # ========================================================================\n","    print(\"\\n\" + \"-\"*80)\n","    print(\"  ANALYSIS\")\n","    print(\"-\"*80)\n","\n","    ket, ssri, neuro = results['ketamine'], results['ssri'], results['neurosteroid']\n","    untreated = results['untreated']\n","\n","    print(\"\\n  1. IMPROVEMENT FROM UNTREATED STATE (Combined Stress):\")\n","    print(f\"     Ketamine:    {untreated['combined']:.1f}% → {ket['combined']:.1f}% (+{ket['combined'] - untreated['combined']:.1f}%)\")\n","    print(f\"     SSRI:        {untreated['combined']:.1f}% → {ssri['combined']:.1f}% (+{ssri['combined'] - untreated['combined']:.1f}%)\")\n","    print(f\"     Neurosteroid:{untreated['combined']:.1f}% → {neuro['combined']:.1f}% (+{neuro['combined'] - untreated['combined']:.1f}%)\")\n","\n","    print(\"\\n  2. STRUCTURAL VS FUNCTIONAL CHANGES:\")\n","    print(f\"     Ketamine sparsity:    {ket['sparsity']:.1f}% (REDUCED from 95%)\")\n","    print(f\"     SSRI sparsity:        {ssri['sparsity']:.1f}% (UNCHANGED)\")\n","    print(f\"     Neurosteroid sparsity:{neuro['sparsity']:.1f}% (UNCHANGED)\")\n","    print(\"\\n     → Ketamine is the ONLY treatment that adds new connections\")\n","\n","    print(\"\\n  3. EXTREME STRESS RESILIENCE (σ=2.5):\")\n","    print(f\"     Ketamine:    {ket['stress_extreme']:.1f}%\")\n","    print(f\"     SSRI:        {ssri['stress_extreme']:.1f}%\")\n","    print(f\"     Neurosteroid:{neuro['stress_extreme']:.1f}%\")\n","\n","    print(\"\\n  4. NEUROSTEROID MEDICATION DEPENDENCE:\")\n","    print(f\"     Combined ON medication:  {neuro['combined']:.1f}%\")\n","    print(f\"     Combined OFF medication: {neuro['off_medication_combined']:.1f}%\")\n","    print(f\"     Extreme ON medication:   {neuro['stress_extreme']:.1f}%\")\n","    print(f\"     Extreme OFF medication:  {neuro['off_medication_extreme']:.1f}%\")\n","\n","    print(\"\\n  5. RELAPSE VULNERABILITY:\")\n","    print(f\"     Ketamine:    {ket['relapse_drop']:.1f}% drop\")\n","    print(f\"     SSRI:        {ssri['relapse_drop']:.1f}% drop\")\n","    print(f\"     Neurosteroid:{neuro['relapse_drop']:.1f}% drop\")\n","\n","    # ========================================================================\n","    # CLINICAL INTERPRETATION\n","    # ========================================================================\n","    print(\"\\n\" + \"-\"*80)\n","    print(\"  CLINICAL INTERPRETATION\")\n","    print(\"-\"*80)\n","\n","    print(\"\"\"\n","  KEY FINDINGS:\n","\n","  1. MECHANISM MATTERS: Different antidepressants work through distinct routes\n","     - Ketamine REBUILDS: Adds new synapses, restores structural density\n","     - SSRIs REFINE: Strengthen existing pathways via gradual adaptation\n","     - Neurosteroids STABILIZE: Damp hyperexcitability, bound activity range\n","\n","  2. SPEED-DURABILITY TRADEOFF:\n","     - Ketamine: Fast onset, durable changes (new structure persists)\n","     - Neurosteroid: Fast onset, medication-dependent (dynamics reset if stopped)\n","     - SSRI: Slow onset, moderate durability (refined weights persist)\n","\n","  3. TREATMENT SELECTION IMPLICATIONS:\n","\n","     ┌──────────────────────────────────────┬──────────────────────────────────┐\n","     │ Clinical Scenario                    │ Suggested Mechanism              │\n","     ├──────────────────────────────────────┼──────────────────────────────────┤\n","     │ Severe, treatment-resistant MDD      │ Ketamine (structural repair)     │\n","     │ Postpartum depression, acute crisis  │ Neurosteroid (rapid stabilize)   │\n","     │ Mild-moderate, first-line            │ SSRI (gradual, acceptable)       │\n","     │ Recurrent with high relapse risk     │ Ketamine (durable structure)     │\n","     │ Hyperexcitable/anxious component     │ Neurosteroid (activity damping)  │\n","     └──────────────────────────────────────┴──────────────────────────────────┘\n","\n","  4. COMBINATION THERAPY RATIONALE:\n","     - Ketamine + SSRI: Structural + neuromodulatory benefits\n","     - Neurosteroid + SSRI: Rapid stabilization while waiting for SSRI onset\n","     - Ketamine + Psychotherapy: New synapses + activity-guided consolidation\n","    \"\"\")\n","\n","    return results\n","\n","\n","# ============================================================================\n","# ENTRY POINT\n","# ============================================================================\n","if __name__ == \"__main__\":\n","    print(\"\\n\" + \"#\"*80)\n","    print(\"#\" + \" \"*78 + \"#\")\n","    print(\"#\" + \" MULTI-MECHANISM ANTIDEPRESSANT COMPARISON \".center(78) + \"#\")\n","    print(\"#\" + \" Ketamine vs SSRI vs Neurosteroid \".center(78) + \"#\")\n","    print(\"#\" + \" \"*78 + \"#\")\n","    print(\"#\"*80)\n","\n","    results = run_multi_mechanism_experiment()\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"  EXPERIMENT COMPLETE\")\n","    print(\"=\"*80 + \"\\n\")"]},{"cell_type":"markdown","source":["# The End"],"metadata":{"id":"tZtObnuA0WxJ"}}]}